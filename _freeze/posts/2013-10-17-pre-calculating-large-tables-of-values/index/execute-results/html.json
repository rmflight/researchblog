{
  "hash": "cf8ec25b26b7f16b65574540ee411340",
  "result": {
    "markdown": "---\ntitle: \"Pre-Calculating Large Tables of Values\"\ndate: 2013-10-17\ncategories: [R, pre-calculations, programming, development, c++]\nsubtitle: |\n  Demonstrating a way to generate a large amount of numbers that otherwise might take a long time to calculate.\n---\n\n\n\n\n\nI'm currently working on a project where we want to know, based on a euclidian distance measure, what is the probability that the value is a match to the another value. *i.e.* given an actual value, and a theoretical value from calculation, what is the probability that they are the same? This can be calculated using a **chi-square** distribution with one degree-of-freedom, easily enough by considering how much of the chi-cdf we are taking up.\n\n```r\npMatch <- 1 - pchisq(distVal, 1)\n```\n\nThe catch is, we want to do this a whole lot of times, in `c++`. We could use the `boost` library to calculate the **chi-square** each time we need it. Or we could generate a lookup table that is able to find the p-value simply based on the distance. This is especially attractive if we have a limit past which we consider the probability of a match as being zero, and if we use enough decimal points that we don't suffer too much in precision.\n\nAlthough our goal is to implement this in **c++**, I also want to prototype, demonstrate and evaluate the approach in `R`.\n\n## R\n\n### Random number set\n\nWe are going to consider 25 (5 standard deviations squared) as our cutoff for saying the probability is zero. So to make sure we are doing all calculations using the exact same thing, we will pre-generate the values for testing on **real** data, in this case a set of 1000000 random numbers from zero to 25.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnPoint <- 1000000\nrandomData <- abs(rnorm(nPoint, mean=5, sd=5)) # take absolute so we have only positive values\nrandomData[randomData > 25] <- 25\nhist(randomData, 100)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/genRandomData-1.png){width=672}\n:::\n:::\n\n\nWe will have three ways to do this in R:\n\n* using the `pchisq` function\n* in a `for` loop\n* as a lookup table\n\nI'm going to create these all as functions, and then time each one using `microbenchmark`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npchisq_baser <- function(randomData) {\n  1 - pchisq(randomData, 1)\n}\n\npchisq_for <- function(randomData){\n  naiveRes <- numeric(length(randomData))\n  for (iP in 1:length(randomData)) {\n    naiveRes[iP] <- 1 - pchisq(randomData[iP], 1)\n  }\n  naiveRes\n}\n\n# creating the lookup table\nnDivision <- 10000\ndof <- 1\nnSD <- 25\nnElements <- nSD * nDivision\nchiVals <- seq(0, nElements, 1) / nDivision\npTable <- 1 - pchisq(chiVals, 1)\n\npchisq_lookup <- function(randomData, lookupTable, nDivision){\n  tableRes = numeric(length(randomData))\n  for (iP in 1:length(randomData)) {\n    tableRes[iP] <- lookupTable[(randomData[iP] * nDivision) + 1]\n  }\n  tableRes\n}\n\nbase_res = pchisq_baser(randomData)\nlookup_res = pchisq_lookup(randomData, pTable, nDivision)\n```\n:::\n\n\nHow long do each of these take?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres = microbenchmark::microbenchmark(\n  base = pchisq_baser(randomData),\n  for_loop = pchisq_for(randomData),\n  lookup = pchisq_lookup(randomData, pTable, nDivision),\n  times = 50\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::autoplot(res)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/show_timings-1.png){width=672}\n:::\n:::\n\n\nWhat about any loss in precision of the values returned?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlookupRawPrecision <- abs(lookup_res - base_res) / base_res * 100\n\nprecTable <- data.frame(org = base_res, table = lookup_res, percError = lookupRawPrecision)\nggplot(precTable, aes(x=org, y=table)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/tablePres-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(precTable, aes(x=org, y=percError)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/tablePres-2.png){width=672}\n:::\n:::\n\n\nSo, according to this, we are only introducing error at 0.7905138%, which isn't much. And the values look like the are well correlated, so we should be good. \n\nNow, how do these approaches compare when using `c++`?\n\n## C++\n\nSo it's a fair comparison, the code below actually writes the `c++` program we are going to use, with the random numbers for the **p-value** calculation stored as part of the code file. \n\nA couple of notes:\n\n1. To be fair, both versions of the code have the set of random numbers and the lookup table as `float` variables, so that there is no difference in each for memory allocation.\n* Neither one stores the results of the calculation, we don't need it for this demonstration.\n\n### Raw calculations\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncppRaw <- c('#include <iostream>',\n               '#include <boost/math/distributions/chi_squared.hpp>',\n               'int nVal = 1000000;',\n               'double dof = 1.0;',\n               'int i;',\n               paste('float randVals[1000000] = {', paste(as.character(randomData), sep=\"\", collapse=\", \"), '};', sep=\"\", collapse=\"\"),\n               paste('float pTable[250001] = {', paste(as.character(pTable), sep=\"\", collapse=\", \"), '};', sep=\"\", collapse=\"\"),\n               'int main() {',\n               'using boost::math::chi_squared_distribution;',\n               'chi_squared_distribution<> myChi(dof);',\n               'for (i = 0; i < nVal; i++){',\n               '1 - cdf(myChi, randVals[i]);',\n               '};',\n               'return(0);',\n               '};')\ncat(cppRaw, sep=\"\\n\", file=\"cppRaw.cpp\")\n\nsystem2(command = \"g++\", args = \"cppRaw.cpp -o cppRaw.out\")\nsystem2(command = \"time\", args = \"./cppRaw.out\", stderr = \"raw_results.txt\")\nreadLines(\"raw_results.txt\", n = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0.45user 0.00system 0:00.45elapsed 100%CPU (0avgtext+0avgdata 7604maxresident)k\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncppLookup <- c('#include <iostream>',\n               '#include <boost/math/distributions/chi_squared.hpp>',\n               'int nVal = 1000000;',\n               'double dof = 1.0;',\n               'int i;',\n               paste('float randVals[1000000] = {', paste(as.character(randomData), sep=\"\", collapse=\", \"), '};', sep=\"\", collapse=\"\"),\n               paste('float pTable[250001] = {', paste(as.character(pTable), sep=\"\", collapse=\", \"), '};', sep=\"\", collapse=\"\"),\n               'int main() {',\n               'using boost::math::chi_squared_distribution;',\n               'chi_squared_distribution<> myChi(dof);',\n               'for (i = 0; i < nVal; i++){',\n               'pTable[(int(randVals[i] * nVal))];',\n               '};',\n               'return(0);',\n               '};')\ncat(cppLookup, sep=\"\\n\", file=\"cppLookup.cpp\")\nsystem2(\"g++\", args = \"cppLookup.cpp -o cppLookup.out\")\nsystem2(\"time\", args = \"./cppLookup.out\", stderr = \"lookup_results.txt\")\nreadLines(\"lookup_results.txt\", n = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0.00user 0.00system 0:00.00elapsed 100%CPU (0avgtext+0avgdata 3528maxresident)k\"\n```\n:::\n:::\n\n\nSo bypassing `boost` in this case is a good thing, we get some extra speed, and reduce a dependency. We have to generate the lookup table first, but the `cpp` file can be generated once, with a static variable in a class that is initialized to the lookup values. We do have some error, but in our case we can live with it, as the relative rankings should still be pretty good.\n\n**Edit 2022-12-02**: When I originally did this, the lookup `R` version was in between the for loop and the base R equivalent, and now it seems the lookup version is actually faster, by a bunch, actually.\nOr I was blinding myself because I wasn't using `microbenchmark`?\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}