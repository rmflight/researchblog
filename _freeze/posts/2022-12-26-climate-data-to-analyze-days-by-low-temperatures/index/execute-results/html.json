{
  "hash": "4a8cf49f9317495d3064356b1946337d",
  "result": {
    "markdown": "---\ntitle: \"Climate Data to Analyze Days by Low Temperatures\"\nsubtitle: |\n  Inspired by XKCD to figure out how to get local temperature data and plot it.\ndate: 2022-12-26\neditor_options: \n       chunk_output_type: console\ncategories: [xkcd, climate-data]\nbibliography: refs.bib\n---\n\n\n\n\n## XKCD?\n\nIn the past few years I've seen a lot of spiral graphs of temperature anomolies, temperature records knit into scarves, among others.\nBut, hats off to Randall Munroe's XKCD, I think this is one of the more useful graphics about local temperature records (full comic in @fig-cold, and inset blown up in @fig-inset) [@xkcdclimate2022].\nI'm not sure why I'm just seeing this comic, as it is listed as comic 1321, and XKCD is up to 2717 as of 2022-12-27, but better late than never!\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Randall Monroe XKCD comic 1321, \"Cold\".](cold.png){#fig-cold width=8in}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Inset from XKCD comic 1321, \"Cold\".](cold_inset.png){#fig-inset width=8in}\n:::\n:::\n\n\nThis very, very quickly shows people that the lows since 2000 have not gone below 0F until very recently, and the frequency of days below 0F in a given year were quickly decreasing.\nI think it's a very effective graphic (and comic).\n\nBut what if we want to generate our own for another location?\n\n## Data\n\nIn the comic, Randall lists the **rcc-acis** as the source of the data.\nI managed to find <https://www.rcc-acis.org/> as the likely source.\nI looked for an API, and found this page [@rccapi].\n\nThe description of the various API end points seems reasonable enough, except we really want to know where and what we are looking for.\n\nI live in Lexington, KY, USA, so I'm going to use that for the following code.\n\nFirst, we need to find the census code for the county we want to search for weather stations in.\n\nWe can find the county codes from the census.gov website [@censusdotgov].\nIn my case, Fayette Co KY is `21,067`, which we will input into the API as `21067` (without the comma).\n\nThen I can go to the rcc-acis API at <http://data.rcc-acis.org/StnMeta?county=21067> and see the list of stations.\n\n```json\n{\"meta\":[\n{\"uid\": 8251, \"ll\": [-84.4994, 38.1336], \"sids\": [\"154748 2\", \"LSFK2 7\"], \"state\": \"KY\", \"elev\": 930.0, \"name\": \"LEXINGTON SPINDLETOP FARM\"},\n{\"uid\": 8252, \"ll\": [-84.5, 38.03333], \"sids\": [\"154741 2\"], \"state\": \"KY\", \"elev\": 1030.0, \"name\": \"LEXINGTON SOLAR RAD\"},\n{\"uid\": 8253, \"ll\": [-84.61138, 38.03391], \"sids\": [\"93820 1\", \"154746 2\", \"LEX 3\", \"72422 4\", \"KLEX 5\", \"USW00093820 6\", \"LEX 7\"], \"state\": \"KY\", \"elev\": 962.0, \"name\": \"LEXINGTON BLUEGRASS AP\"},\n{\"uid\": 8387, \"ll\": [-84.53333, 38.1], \"sids\": [\"153408 2\", \"USC00153408 6\"], \"state\": \"KY\", \"elev\": 947.0, \"name\": \"GREENDALE\"},\n{\"uid\": 31507, \"ll\": [-84.52694, 38.01556], \"sids\": [\"154736 2\", \"LEXK2 7\"], \"state\": \"KY\", \"elev\": 987.0, \"name\": \"LEXINGTON 3 SE\"},\n{\"uid\": 40338, \"ll\": [-84.36667, 38.0], \"sids\": [\"151548 2\"], \"state\": \"KY\", \"name\": \"CHILESBURGH\"},\n{\"uid\": 53409, \"ll\": [-84.5097, 37.98434], \"sids\": [\"US1KYFY0001 6\", \"KYFY0001 10\"], \"state\": \"KY\", \"elev\": 951.0, \"name\": \"LEXINGTON 4.9 SW\"},\n{\"uid\": 53410, \"ll\": [-84.48511, 37.96729], \"sids\": [\"US1KYFY0002 6\", \"KYFY0002 10\"], \"state\": \"KY\", \"elev\": 981.0, \"name\": \"LEXINGTON-FAYETTE 6.3 S\"},\n{\"uid\": 53411, \"ll\": [-84.51874, 38.01625], \"sids\": [\"US1KYFY0003 6\", \"KYFY0003 10\"], \"state\": \"KY\", \"elev\": 1004.0, \"name\": \"LEXINGTON 3.7 WSW\"},\n{\"uid\": 53412, \"ll\": [-84.49503, 38.02486], \"sids\": [\"US1KYFY0009 6\", \"KYFY0009 10\"], \"state\": \"KY\", \"elev\": 1010.0, \"name\": \"LEXINGTON 1.7 SSE\"},\n{\"uid\": 53413, \"ll\": [-84.4816, 37.9876], \"sids\": [\"US1KYFY0012 6\", \"KYFY0012 10\"], \"state\": \"KY\", \"elev\": 929.0, \"name\": \"LEXINGTON-FAYETTE 4.0 SSW\"},\n{\"uid\": 53414, \"ll\": [-84.51935, 38.01643], \"sids\": [\"US1KYFY0014 6\", \"KYFY0014 10\"], \"state\": \"KY\", \"elev\": 999.0, \"name\": \"LEXINGTON 1.7 SW\"},\n{\"uid\": 69236, \"ll\": [-84.53672, 38.05231], \"sids\": [\"US1KYFY0019 6\", \"KYFY0019 10\"], \"state\": \"KY\", \"elev\": 957.0, \"name\": \"LEXINGTON 4.3 W\"},\n{\"uid\": 82402, \"ll\": [-84.45337, 37.99841], \"sids\": [\"US1KYFY0023 6\", \"KYFY0023 10\"], \"state\": \"KY\", \"elev\": 1045.0, \"name\": \"LEXINGTON 4.2 SSE\"},\n{\"uid\": 86252, \"ll\": [-84.41615, 38.04699], \"sids\": [\"US1KYFY0027 6\", \"KYFY0027 10\"], \"state\": \"KY\", \"elev\": 947.0, \"name\": \"LEXINGTON 4.7 E\"},\n{\"uid\": 86818, \"ll\": [-84.51712, 37.97325], \"sids\": [\"US1KYFY0029 6\", \"KYFY0029 10\"], \"state\": \"KY\", \"elev\": 974.0, \"name\": \"LEXINGTON 5.7 SSW\"},\n{\"uid\": 89211, \"ll\": [-84.55495, 37.97623], \"sids\": [\"US1KYFY0032 6\", \"KYFY0032 10\"], \"state\": \"KY\", \"elev\": 975.0, \"name\": \"LEXINGTON 6.9 SW\"},\n{\"uid\": 93426, \"ll\": [-84.52242, 37.98129], \"sids\": [\"US1KYFY0036 6\", \"KYFY0036 10\"], \"state\": \"KY\", \"elev\": 993.0, \"name\": \"LEXINGTON 4.8 S\"},\n{\"uid\": 101642, \"ll\": [-84.44324, 38.05104], \"sids\": [\"US1KYFY0040 6\", \"KYFY0040 10\"], \"state\": \"KY\", \"elev\": 953.0, \"name\": \"LEXINGTON 3.3 E\"},\n{\"uid\": 102039, \"ll\": [-84.54735, 37.9821], \"sids\": [\"US1KYFY0041 6\", \"KYFY0041 10\"], \"state\": \"KY\", \"elev\": 996.0, \"name\": \"LEXINGTON 4.5 SSW\"}]}\n```\n\nThe easiest, and likely most consistent location for me to use is the Bluegrass Airport, which has UID `8253`.\n\nLet's pull the json data for daily maximum and minimum temperatures since 1970 to yesterday (2022-12-25) using this json query:\n\n```\nhttp://data.rcc-acis.org/StnData?uid=8253&sdate=1970-01-01&edate=2022-12-25&elems=1,2\n```\n\nWe can pull all that data into R directly using:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp_data = jsonlite::fromJSON(\"http://data.rcc-acis.org/StnData?uid=8253&sdate=1970-01-01&edate=2022-12-25&elems=1,2\")\n```\n:::\n\n\nI'm actually going to cache that data in a local file, so I'm not making 20 pulls while I'm writing this blog post.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp_data = jsonlite::fromJSON(\"bluegrass_dailytemps.json\")\nstr(temp_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 2\n $ meta:List of 6\n  ..$ uid  : int 8253\n  ..$ ll   : num [1:2] -84.6 38\n  ..$ sids : chr [1:7] \"93820 1\" \"154746 2\" \"LEX 3\" \"72422 4\" ...\n  ..$ state: chr \"KY\"\n  ..$ elev : num 962\n  ..$ name : chr \"LEXINGTON BLUEGRASS AP\"\n $ data: chr [1:19352, 1:3] \"1970-01-01\" \"1970-01-02\" \"1970-01-03\" \"1970-01-04\" ...\n```\n:::\n:::\n\n\nWe've got some metadata about the station we pulled from, and then a matrix of dates and daily maximum and minimum recorded temperatures.\nWe'll turn that into a `tibble` and convert the dates to something more useful.\nI'm going to aggregate by year to make this easy.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nlibrary(ggplot2)\ntheme_set(cowplot::theme_cowplot())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbluegrass_df = tibble::as_tibble(temp_data$data)\nnames(bluegrass_df) = c(\"date\", \"max\", \"min\")\nbluegrass_df = bluegrass_df |>\n  dplyr::mutate(date2 = lubridate::as_date(date),\n                year = lubridate::year(date2),\n                month = lubridate::month(date2),\n                ym = paste0(year, \"-\", month))\nbluegrass_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 19,352 × 7\n   date       max   min   date2       year month ym    \n   <chr>      <chr> <chr> <date>     <dbl> <dbl> <chr> \n 1 1970-01-01 33    23    1970-01-01  1970     1 1970-1\n 2 1970-01-02 34    23    1970-01-02  1970     1 1970-1\n 3 1970-01-03 26    15    1970-01-03  1970     1 1970-1\n 4 1970-01-04 35    14    1970-01-04  1970     1 1970-1\n 5 1970-01-05 44    23    1970-01-05  1970     1 1970-1\n 6 1970-01-06 34    11    1970-01-06  1970     1 1970-1\n 7 1970-01-07 11    -6    1970-01-07  1970     1 1970-1\n 8 1970-01-08 3     -5    1970-01-08  1970     1 1970-1\n 9 1970-01-09 8     -3    1970-01-09  1970     1 1970-1\n10 1970-01-10 18    -6    1970-01-10  1970     1 1970-1\n# … with 19,342 more rows\n```\n:::\n:::\n\n\nLet's count how many days a year a minimum was below a set temperature.\nSimilar to XKCD, I'll try a cutoff of 0F (see @fig-lex-below_0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncutoff = 0\nbluegrass_0 = bluegrass_df |>\n  dplyr::mutate(below_cutoff = min < cutoff) |>\n  dplyr::group_by(year) |>\n  dplyr::summarize(nday = sum(below_cutoff)) |>\n  dplyr::ungroup() #|>\n  #dplyr::mutate(ym = lubridate::ym(ym))\n\n\nbluegrass_0 |>\n  ggplot(aes(x = year, y = nday)) +\n  geom_col() +\n  labs(subtitle = \"No. days < 0F at Bluegrass Airport Lexington.\",\n       x = \"Year\", y = \"No. of Days < 0F\")\n```\n\n::: {.cell-output-display}\n![Number of days < 0F at Bluegrass International Airport (LEX) by year since 1970.](index_files/figure-html/fig-lex-below_0-1.png){#fig-lex-below_0 width=672}\n:::\n:::\n\n\nNice.\nDefinitely fewer days at less than 0F in more recent times than previously.\n\n## Double Check Using Lambert Airport in St. Louis\n\nBut how do I know it's probably right?\nWe can double check if I get a very similar plot to the XKCD one when using the data from St. Louis' Lambert Airport, as shown in @fig-lambert.\nI went through the same procedure as above to find the county code for St. Louis, and then the UID for Lambert Airport, and saved the JSON.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp_lambert = jsonlite::fromJSON(\"lambert_stlous_dailytemps.json\")\nlambert_df = tibble::as_tibble(temp_lambert$data)\nnames(lambert_df) = c(\"date\", \"max\", \"min\")\nlambert_df = lambert_df |>\n  dplyr::mutate(date2 = lubridate::as_date(date),\n                year = lubridate::year(date2),\n                month = lubridate::month(date2),\n                ym = paste0(year, \"-\", month))\nlambert_0 = lambert_df |>\n  dplyr::mutate(below_cutoff = min < cutoff) |>\n  dplyr::group_by(year) |>\n  dplyr::summarize(nday = sum(below_cutoff)) |>\n  dplyr::ungroup()\n\n\nlambert_0 |>\n  ggplot(aes(x = year, y = nday)) +\n  geom_col() +\n  labs(subtitle = \"No. days < 0F at Lambert Airport St. Louis.\",\n       x = \"Year\", y = \"No. of Days < 0F\")\n```\n\n::: {.cell-output-display}\n![Number of days < 0F at Lambert Airport by month since 1970.](index_files/figure-html/fig-lambert-1.png){#fig-lambert width=672}\n:::\n:::\n\n\nSo @fig-lambert is **similar** to the one from XKCD, but I'd really like to see the data file they used and which station.\nI also think they probably used only the fall and winter months for a given year, like December to February, and that was the count for that particular year, excluding the next December.\nRegardless, the frequency of days where the minimum was below 0F has dropped significantly since the 80's and 90's, whether here in Lexington or St. Louis.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}