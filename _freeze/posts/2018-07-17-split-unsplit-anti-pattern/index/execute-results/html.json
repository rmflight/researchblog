{
  "hash": "d25a3814d9ce68a5ba6c9b9162831141",
  "result": {
    "markdown": "---\ntitle: \"Split - Unsplit Anti-Pattern\"\ndate: '2018-07-17'\ncategories: [R, development, programming, purrr, dplyr, join] \nsubtitle: |\n  Getting some speed using dplyr::join than my more intuitive split --> unsplit pattern.\n---\n\n\n## TL;DR\n\nIf you notice yourself using `split` -> `unsplit` / `rbind` on two object to\nmatch items up, maybe you should be using `dplyr::join_` instead. Read below\nfor concrete examples.\n\n## Motivation\n\nI have had a lot of calculations lately that involve some sort of `normalization`\nor scaling a group of related values, each group by a different factor.\n\nLets setup an example where we will have `1e5` values in `10` groups, each group\nof values being `normalized` by their own value.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\nlibrary(profvis)\nset.seed(1234)\nn_point <- 1e5\nto_normalize <- data.frame(value = rnorm(n_point), group = sample(seq_len(10), n_point, replace = TRUE))\n\nnormalization <- data.frame(group = seq_len(10), normalization = rnorm(10))\n```\n:::\n\n\nFor each `group` in `to_normalize`, we want to apply the normalization factor in\n`normalization`. In this case, I'm going to do a simple subtraction.\n\n\n## Match Them!\n\nMy initial implementation was to iterate over the groups, and use `%in%` to\n`match` each `group` from the normalization factors and the data to be normalized,\nand modify in place. **Don't do this!!** It was\nthe slowest method I've used in my real package code!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmatch_normalization <- function(normalize_data, normalization_factors){\n  use_groups <- normalization_factors$group\n  \n  for (igroup in use_groups) {\n    normalize_data[normalize_data$group %in% igroup, \"value\"] <- \n      normalize_data[normalize_data$group %in% igroup, \"value\"] - normalization_factors[normalization_factors$group %in% igroup, \"normalization\"]\n  }\n  normalize_data\n}\n```\n:::\n\n\n```{.r .cell-code}\nmicro_results <- summary(microbenchmark(match_normalization(to_normalize, normalization)))\nknitr::kable(micro_results)\n```\n\n::: {.cell-output-display}\n|expr                                             |      min|       lq|     mean|   median|       uq|      max| neval|\n|:------------------------------------------------|--------:|--------:|--------:|--------:|--------:|--------:|-----:|\n|match_normalization(to_normalize, normalization) | 49.75035| 53.45793| 57.42852| 54.73885| 57.50818| 115.9432|   100|\n:::\n\n\nNot bad for the test data. But can we do better?\n\n## Split Them!\n\nMy next thought was to split them by their `group`s, and then iterate again over\nthe groups using `purrr::map`, and then unlist them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit_normalization <- function(normalize_data, normalization_factors){\n  split_norm <- split(normalization_factors$normalization, normalization_factors$group)\n  \n  split_data <- split(normalize_data, normalize_data$group)\n  \n  out_data <- purrr::map2(split_data, split_norm, function(.x, .y){\n    .x$value <- .x$value - .y\n    .x\n  })\n  do.call(rbind, out_data)\n}\n```\n:::\n\n\n```{.r .cell-code}\nmicro_results2 <- summary(microbenchmark(match_normalization(to_normalize, normalization),\n               split_normalization(to_normalize, normalization)))\nknitr::kable(micro_results2)\n```\n\n::: {.cell-output-display}\n|expr                                             |       min|       lq|      mean|    median|        uq|      max| neval|\n|:------------------------------------------------|---------:|--------:|---------:|---------:|---------:|--------:|-----:|\n|match_normalization(to_normalize, normalization) |  54.09506|  69.0412|  75.46899|  73.44315|  78.03191| 160.8331|   100|\n|split_normalization(to_normalize, normalization) | 103.18837| 133.9091| 141.51288| 142.00616| 148.73655| 197.9781|   100|\n:::\n\n\n## Join Them!\n\nMy final thought was to join the two data.frame's together using `dplyr`, and then\nthey are automatically matched up.\n\n\n::: {.cell}\n\n```{.r .cell-code}\njoin_normalization <- function(normalize_data, normalization_factors){\n  normalize_data <- dplyr::right_join(normalize_data, normalization_factors,\n                                      by = \"group\")\n  \n  normalize_data$value <- normalize_data$value - normalize_data$normalization\n  normalize_data[, c(\"value\", \"group\")]\n}\n```\n:::\n\n\n```{.r .cell-code}\nmicro_results3 <- summary(microbenchmark(match_normalization(to_normalize, normalization),\n               split_normalization(to_normalize, normalization),\n               join_normalization(to_normalize, normalization)))\nknitr::kable(micro_results3)\n```\n\n::: {.cell-output-display}\n|expr                                             |       min|        lq|      mean|    median|        uq|      max| neval|\n|:------------------------------------------------|---------:|---------:|---------:|---------:|---------:|--------:|-----:|\n|match_normalization(to_normalize, normalization) |  56.04426|  68.50138|  77.23205|  74.45665|  82.25683| 184.9358|   100|\n|split_normalization(to_normalize, normalization) | 106.96651| 135.82308| 148.88644| 145.27503| 154.41702| 284.8173|   100|\n|join_normalization(to_normalize, normalization)  |  11.60424|  13.26513|  21.29059|  14.18384|  15.38526| 488.3713|   100|\n:::\n\n\n## Conclusions\n\nSo on my computer, the `split` and `match` implementations are mostly comparable,\nalthough on my motivating real world example, I actually got a 3X speedup by\nusing the `split` method. That may be because of issues related to `DataFrame`\nand matching elements within that structure. The `join` method is 10-14X faster\nthan the others, which is what I've seen in my motivating work. I also think\nit makes the code easier to read and reason over, because you can see what\nis being subtracted from what directly in the code.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}