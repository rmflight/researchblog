{
  "hash": "3a629f352770a5eaae75d51dc63b81a2",
  "result": {
    "markdown": "---\ntitle: \"Journal Impact Factor Distributions\"\nsubtitle: |\n  Discovering that journal impact factor distributions are log-normal.\ndate: 2022-12-25\neditor_options: \n  chunk_output_type: console\ncategories: [impact-factor]\nbibliography: refs.bib\n---\n\n\n## TL;DR\n\nJournal impact factor distributions seem to be log-normal.\nIf we **decide** they should be used, then at the very least, they should be log-transformed before doing any calculations with them.\n\n## Journal Impact Factor\n\nAt some point in history, someone decided that we could **measure** how important a journal is by the number of citations the manuscripts within it get.\nOf course this is ridiculous on it's face, but over time those journals with higher impact factors have become **more important** and **prestigous** to publish in.\nIn fact, instead of judging each others work on the publications themselves, academia started doing this thing where we instead judge papers (and academics) by **where** they are published and the publications journal impact factors (JIF).\nMost publishers make a big deal out of announcing their journals JIF and report them to the 3rd decimal place.\nStupid, I know, but here we are.\nEven more ridiculous, Thomson Reuters makes big money counting all of these citations, calculating the JIF and selling the data to others.\n\n## Larivi{\\`e}re et al\n\nWay back in 2016, Larivi`ere et al published a nice paper on the distributions of journal impact factors and how to compare them [@Lariviere062109].\nI heartily recommend you check that publication out.\nI'm not going to discuss this manuscript in particular, except to note two things:\n\n1. that they provided a very nice description of how to acquire and calculate citation counts from a service such as Thomson Reuters Web of Science.\n1. when I look at their graphs, I thought they looked likely to be log-normal (see @fig-larivier-graph).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Figure 1 from Lariviere et al: Citation distributions of 11 different science journals. Citations are to citable documents as classified by Thomson Reuters, which include standard research articles and reviews. The distributions contain citations accumulated in 2015 to citable documents published in 2013 and 2014 in order to be comparable to the 2015 JIFs published by Thomson Reuters. To facilitate direct comparison, distributions are plotted with the same range of citations (0-100) in each plot; articles with more than 100 citations are shown as a single bar at the right of each plot.](leviervre-F1.large.jpg){#fig-larivier-graph width=513}\n:::\n:::\n\n\n## Getting Data\n\nUnfortunately, Larivi{\\`e}re et al didn't provide their data.\nWhich makes sense, it's from a closed source.\nHowever, I used their description of getting the data from Web of Science, and went and created my own version of the data for a set of journals so I could do my own analysis.\n\nFollowing the guide provided in the Appendix of [@Lariviere062109], I went into Web Of Science and produced citation reports for 7 journals (eLife, EMBO Journal, Nature, Nature Communications, PLOS Biology, PLOS Genetics, and Science), and saved them. \nUnfortunately, the preprint shows data for publications published in 2013-2014, but the guide showed 2012-2013, so I ended up downloading the citation data for publications published in 2012-2013, which would have influenced the 2014 JIF.\nHowever, I think the conclusions are the same.\n\nIf you want the original data I acquired, you can go check out [@Flight2021].\n\n## Raw Plots\n\nSo lets load up the data and plot the citation counts for each journal, as shown in @fig-raw-counts.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Raw citation counts for chosen journals for 2012-2013.](index_files/figure-html/fig-raw-counts-1.png){#fig-raw-counts width=672}\n:::\n:::\n\n\nI think these still look pretty similar to those shown in @fig-larivier-graph.\nWe can see that the means are heavily influenced by the very long tails in these graphs.\n\n## Log Transform\n\nNow, lets log-transform them, and calculate summary statistics on the log-transformed data, as shown in @fig-log-counts.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Log citation counts for chosen journals for 2012-2013](index_files/figure-html/fig-log-counts-1.png){#fig-log-counts width=672}\n:::\n:::\n\n\nThese look much more normal, at least for some of the heavily cited journals like Nature and Science.\n\nSo, if we are going to continue using these kinds of metrics, we should either adopt the metrics that Larivi`ere propose, or at the very least log-transform the citation counts.\n\nOr we could drop them altogher.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}