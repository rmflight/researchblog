{
  "hash": "08e6ac1abb2ec9c011e6309b1524a0f3",
  "result": {
    "markdown": "---\ntitle: \"Creating an Analysis With a targets Workflow\"\nsubtitle: |\n  How I work through an -omics analysis using the targets package.\ndate: 2022-09-27\ncategories: [analysis, development, mass-spectrometry, targets]\n---\n\n\n## TL;DR\n\nSetting up an analysis workflow using `{targets}` can be a little confusing without worked examples.\nThis is my attempt to provide such an example.\n\n## Example Repo\n\nI've set up a [GitHub repo](https://github.com/rmflight/example_targets_workflow) that contains the data and scripts used for this analysis.\n\n## Packages\n\nFor this example, if you want to follow along yourself, you will need Miles McBain's `{tflow}` package, which sets up an opinionated but loose directory / file structure.\nYou will also need the `{targets}` package, and `{tarchetypes}`, and `{rmarkdown}`, as well as a few others.\n\n```r\ninstall.packages(\n c(\"conflicted\",\n   \"dotenv\",\n   \"targets\",\n   \"tarchetypes\",\n   \"BiocManager\",\n   \"viridis\")\n)\n\nBiocManager::install(\"limma\")\n\nremotes::install_github(\n  c(\"milesmcbain/tflow\",\n    \"moseleyBioinformaticsLab/ICIKendallTau\",\n    \"moseleyBioinformaticsLab/visualizationQualityControl\"))\n```\n\n## Example Analysis\n\nThe example we will work through is a lipidomics data analysis.\nThis data is based on real data, but sample IDs have been completely anonymized.\nI'm going to walk through all the steps I do to set up the analysis, mostly by commenting the example `_targets.R` file, and leaving the objects in the order they were created.\n\n### Create New Project\n\nWe start by creating a brand new RStudio project to work in, or any new directory.\n\n### Initialize tflow\n\n```r\ntflow::use_tflow()\n✔ Setting active project to '/home/rmflight/Projects/personal/example_targets_workflow'\n✔ Creating 'R/'\n✔ Writing 'packages.R'\n✔ Writing '_targets.R'\n✔ Writing '.env'\n```\n\nIn addition to this, I've created a `data` directory, and added the measurements CSV and metadata CSV to that directory.\n\n```r\ndir(\"data\")\n[1] \"sample_measurements.csv\" \"sample_metadata.csv\"\n```\n\nSome important things about using `{tflow}` in this project:\n\n  * `{tflow}` uses the `targets::tar_plan()` function to contain the various targets in the workflow.\n  * This means you don't have to have a list of targets at the end of `_targets.R`.\n  * It also means you can use `{drake}` style targets of the form:\n  \n```r\n out_target = function_name(in_target),\n ...\n```\n\nI personally think it makes the workflow much more readable than the default targets style of:\n\n```r\ntar_target(\n  out_target\n  function_name(in_target)\n)\n```\n\n### Setup Packages\n\nWe modify the `packages.R` file to add anything else we need.\n\n```r\n## library() calls go here\nlibrary(conflicted)\nlibrary(dotenv)\nlibrary(targets)\nlibrary(tarchetypes)\n# our extra packages for this analysis\nlibrary(visualizationQualityControl)\nlibrary(ggplot2)\nlibrary(ICIKendallTau)\nlibrary(dplyr)\nlibrary(limma)\n```\n\n### Initial _targets.R\n\nThis is what `{tflow}` sets up to run when you start.\n\n```r\n## Load your packages, e.g. library(targets).\nsource(\"./packages.R\")\n\n## Load your R files\nlapply(list.files(\"./R\", full.names = TRUE), source)\n\n## tar_plan supports drake-style targets and also tar_target()\ntar_plan(\n\n# target = function_to_make(arg), ## drake style\n\n# tar_target(target2, function_to_make2(arg)) ## targets style\n\n)\n```\n\nNotice that the first thing that happens is that the `packages.R` file gets sourced, so that all your packages are loaded.\nSecond, it runs through all of the files in `R`, and sources them to load all the functions.\n`{tflow}` and `{targets}` expound a functional workflow, where we put things in functions.\nFinally, it uses `tar_plan()` to run each of the targets.\n\nWe will specify each of the targets in turn to fill out the analysis we want to do.\n\n### Load Data\n\nLets first **declare** the measurement file and metadata file as actual targets, so if they change, then any dependent targets will be re-run as well.\n\n```r\ntar_plan(\n\n  tar_target(measurement_file,\n             \"data/sample_measurements.csv\",\n             format = \"file\"),\n  tar_target(metadata_file,\n             \"data/sample_metadata.csv\",\n             format = \"file\")\n\n)\n```\n\nRunning it with `tar_make()` results in:\n\n```r\ntar_make()\n• start target measurement_file\n• built target measurement_file [0.001 seconds]\n• start target metadata_file\n• built target metadata_file [0.001 seconds]\n• end pipeline [0.078 seconds]\n```\n\nThen we add in actually reading in the data.\n\n```r\ntar_plan(\n\n  tar_target(measurement_file,\n             \"data/sample_measurements.csv\",\n             format = \"file\"),\n  tar_target(metadata_file,\n             \"data/sample_metadata.csv\",\n             format = \"file\")\n\n  lipid_measurements = readr::read_csv(measurement_file),\n  lipid_metadata = readr::read_csv(metadata_file),\n\n)\n```\n\n```r\ntar_make()\n✔ skip target measurement_file\n✔ skip target metadata_file\n• start target lipid_measurements\nRows: 1012 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): class, name, group_units, feature_id\ndbl (12): WT_1, WT_2, WT_3, WT_4, WT_5, WT_6, KO_1, KO_2, KO_3, KO_4, KO_5, ...\n|\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n• built target lipid_measurements [0.305 seconds]\n• start target lipid_metadata\nRows: 12 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): parent_sample_name, assay, cell_line, client_matrix, client_sample...\ndbl  (8): client_identifier, client_sample_number, group_number, sample_amou...\n/\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n• built target lipid_metadata [0.07 seconds]\n• end pipeline [0.47 seconds]\n```\n\n### Exploratory Data Analysis\n\nFor the exploratory data analysis (EDA), I like to put that into a report.\nYou set those up using `tflow::use_rmd(\"document_name\")` or `tflow::use_qmd(\"document_name)`.\nAn example [EDA report](https://github.com/rmflight/example_targets_workflow/blob/main/doc/exploration.Rmd) is available at the actual repo.\n\n```r\ntflow::use_rmd(\"exploration\")\n✔ Setting active project to '/home/rmflight/Projects/personal/example_targets_workflow'\n✔ Writing 'doc/exploration.Rmd'\nAdd this target to your tar_plan():\n\ntar_render(exploration, \"doc/exploration.Rmd\")\n```\n\n```r\ntar_plan(\n\n  tar_target(measurement_file,\n             \"data/sample_measurements.csv\",\n             format = \"file\"),\n  tar_target(metadata_file,\n             \"data/sample_metadata.csv\",\n             format = \"file\")\n\n  lipid_measurements = readr::read_csv(measurement_file),\n  lipid_metadata = readr::read_csv(metadata_file),\n  \n  tar_render(exploration, \"doc/exploration.Rmd\")\n)\n```\n\n```r\n> targets::tar_make()\n✔ skip target measurement_file\n✔ skip target metadata_file\n✔ skip target lipid_measurements\n✔ skip target lipid_metadata\n• start target exploration\n• built target exploration [2.829 seconds]\n• end pipeline [2.922 seconds]\n```\n\nNote we could have put these bits in their own functions instead of keeping them in the document proper:\n  \n  * ICI-Kt correlations;\n  * Heatmap figure;\n  * PCA decomposition;\n  * PCA visualization\n  \nThese are left as an exercise for the reader.\n\n### Differential Analysis\n\nFollowing EDA, we need to do the differential analysis.\nBut for that, we need to do normalization and imputation of missing values first.\nEach one of those should be their own functions.\n[Here](https://github.com/rmflight/example_targets_workflow/blob/main/R/differential.R#L1) is the normalization function, [here](https://github.com/rmflight/example_targets_workflow/blob/main/R/differential.R#L26) is the imputation, and [here](https://github.com/rmflight/example_targets_workflow/blob/main/R/differential.R#L41) is the differential analysis function.\n\nAnd here is the output of running each step.\n\n```r\n# normalization\n> tar_make()\n✔ skip target measurement_file\n✔ skip target metadata_file\n✔ skip target lipid_measurements\n✔ skip target lipid_metadata\n• start target lipid_normalized\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n• `` -> `...9`\n• `` -> `...10`\n• `` -> `...11`\n• `` -> `...12`\n• built target lipid_normalized [0.449 seconds]\n✔ skip target exploration\n• end pipeline [0.562 seconds]\n```\n\n```r\n# imputing missing values\n> tar_make()\n✔ skip target measurement_file\n✔ skip target metadata_file\n✔ skip target lipid_measurements\n✔ skip target lipid_metadata\n✔ skip target lipid_normalized\n✔ skip target exploration\n• start target lipid_imputed\n• built target lipid_imputed [0.05 seconds]\n• end pipeline [0.169 seconds]\n```\n\n```r\n# differential analysis\n> tar_make()\n✔ skip target measurement_file\n✔ skip target metadata_file\n✔ skip target lipid_measurements\n✔ skip target lipid_metadata\n✔ skip target lipid_normalized\n✔ skip target exploration\n✔ skip target lipid_imputed\n• start target lipids_differential\n• built target lipids_differential [0.198 seconds]\n• end pipeline [0.312 seconds]\n```\n\nI **try** to build it up piecewise like this because it lets me easily load the previous target into the next function.\nMost of my functions will have `tar_load(previous_target)` at the top as a comment, or `varname = tar_read(previous_target)`, if I've got a more generic variable name I want to use that doesn't match the name of the target coming into the function.\nFor example, here is the top of the normalization function.\n\n```r\nnormalize_samples = function(lipid_measurements){\n  # do normalization in here and return the df\n  # tar_load(lipid_measurements)\n...\n```\n\nThis strategy lets me easily load the variables I need in that function space and develop the actual code of the function.\nI will very often couple this with restarting the R session, `source(\"./packages.R\")`, and if needed `lapply(...)` sourcing the R function files, and then load the necessary variables and start writing the code for the function.\n\n### Final Report\n\nFinally, we can put the differential results in our final report.\nSo that they are together, we can make the EDA report a **child document** of the differential report, and include it as well.\nLet's actually make a copy, and include it as a child document.\n\nWe add it to the plan as another target using the `tar_target` syntax, because as far as I know that is the only way to include something as a file dependency.\nIf we want the **differential_report** target to get rerun when the *exploration* one is changed, this is the way to do it, have a target in the `tar_plan`, and then make sure to load the target in the *differential_report* itself.\n\n```r\n# on the command line / terminal / console\n>tflow::use_rmd(\"differential_report\")\n✔ Writing 'doc/differential_report.Rmd'\nAdd this target to your tar_plan():\n\ntar_render(differential_report2, \"doc/differential_report.Rmd\")\n```\n\n```r\n# in the _targets.R file\n# add the child target\ntar_target(exploration_child,\n             \"doc/exploration_child.Rmd\",\n             format = \"file\"),\n             \n# and then generate final report\ntar_render(differential_report, \"doc/differential_report.Rmd\")\n```\n\nIn the rmarkdown:\n\n````markdown\n```{r eda child='doc/exploration_child.Rmd'}\nplot(cars)\n```\n````\n\n```r\n# run the differential report\n> tar_make()\n✔ skip target measurement_file\n✔ skip target metadata_file\n✔ skip target exploration_child\n✔ skip target lipid_measurements\n✔ skip target lipid_metadata\n✔ skip target lipid_normalized\n✔ skip target exploration\n✔ skip target lipid_imputed\n✔ skip target lipids_differential\n• start target differential_report\n• built target differential_report [3.018 seconds]\n• end pipeline [3.14 seconds]\n```\n\n\n## Notes About Rmarkdown and Quarto\n\nIf you want to be able to interactively mess with your Rmarkdown / Quarto docs while under `{targets}`, then you need to change the setting **Chunk Output Inline** to **Chunk Output in Console**.\n\nIf you want to run a full render of the document **outside** of the `{targets}` workflow, then you have to add an option to the **interactive** (shell, console) calls to `{rmarkdown}` and `{quarto}` to either use the `knit_root_dir` or `execute_dir` arguments, respectively.\nBoth of those should be in the top level directory of the `{targets}` project, which most often at the console can be gotten by using `getwd()`, as shown in the examples below.\n\n```r\n# for rmarkdown\nrmarkdown::render(\"doc/document.Rmd\", knit_root_dir = getwd())\n# for quarto\nquarto::quarto_render(\"doc/document.qmd\", execute_dir = getwd())\n```\n\nThere is also currently an issue with using `{gt}` tables in Quarto -> Word documents within `{targets}` workflows that as of 2022-09-27, is not quite resolved.\n\n*Edited 2022-11-30:* Added a couple of notes on the use of `{tflow}` and subsequently `tar_plan()`\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}